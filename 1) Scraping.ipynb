{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Content\n",
    "Files prepared: \n",
    "* stock_list.xlsx = 3800 stock names + exchange names\n",
    "* names_all.xlsx = 3208 stock names + Indicies\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Installing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.) General\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure  \n",
    "import numpy as np\n",
    "import math\n",
    "from pandas import DataFrame\n",
    "from math import sqrt\n",
    "from datetime import datetime\n",
    "import csv\n",
    "import time\n",
    "from datetime import date\n",
    "\n",
    "# 2.) Scrapping\n",
    "import requests                  \n",
    "import lxml.html as lh\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.action_chains import ActionChains      # ?????\n",
    "from time import sleep\n",
    "\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Loading list of 3800 stock names and exchanges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"C:/Users/Desktop/Python/stocks/\"\n",
    "\n",
    "names = pd.read_excel(path + \"stock_list.xlsx\" )\n",
    "names.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Scraping Indicies from Yahoo Finance\n",
    "### 4-5 hours !!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def get_indicies(stock_names):\n",
    "    \n",
    "    names = []\n",
    "     \n",
    "    # open browser    \n",
    "    browser = webdriver.Chrome()\n",
    "    url = \"https://finance.yahoo.com\"\n",
    "    browser.get(url)\n",
    "    \n",
    "    # click on AGREE - might be changed time by time\n",
    "    agree = browser.find_elements_by_xpath(\"/html/body/div/div/div/div/div[2]/div[2]/form/button\")[0]\n",
    "    hover = ActionChains(browser).move_to_element(agree)\n",
    "    hover.perform()\n",
    "    agree.click()\n",
    "    \n",
    "    # The whole loop is processed in a single browser window\n",
    "    for i in range(len(stock_names)):      \n",
    "        \n",
    "        # Click to the search row\n",
    "        find_stock = browser.find_elements_by_xpath('/html/body/div[1]/div/div/div[1]/div/div[1]/div[1]/div/div/div[1]/div/div/div/div[1]/div/div[2]/div/form/input[1]')[0]\n",
    "        hover = ActionChains(browser).move_to_element(find_stock)\n",
    "        hover.perform()\n",
    "        find_stock.click()\n",
    "        \n",
    "        # Insert stock name\n",
    "        find_stock.send_keys(stock_names.loc[i].Names)  \n",
    "        ### ILOC works with the real index of the row (starts with 0), while LOC works with the original values, before slicing (until we reset index)\n",
    "        ### in this case both can be used\n",
    "            \n",
    "        time.sleep(1)\n",
    "        ### Helps a little, but still, sometimes the last searched value is automatically put in the search row... could be checked in the end\n",
    "        \n",
    "        # try click on Search button\n",
    "        try: \n",
    "            find_button = browser.find_elements_by_xpath(\"/html/body/div[1]/div/div/div[1]/div/div[1]/div[1]/div/div/div[1]/div/div/div/div[1]/div/div[2]/div/form/div[1]/button\")[0]\n",
    "            hover = ActionChains(browser).move_to_element(find_button)\n",
    "            hover.perform()\n",
    "            find_button.click()\n",
    "\n",
    "        # Wait a sec; If there is a name, take it\n",
    "            time.sleep(1)\n",
    "            name = browser.find_element_by_xpath(\"/html/body/div[1]/div/div/div[1]/div/div[2]/div/div/div[4]/div/div/div/div[2]/div[1]/div[1]/h1\").text\n",
    "            names.append(name)\n",
    "            \n",
    "        # If failed, save error and open the browser, again\n",
    "        except:\n",
    "            names.append(\"error\")\n",
    "            url = \"https://finance.yahoo.com\"\n",
    "            browser.get(url)\n",
    "    \n",
    "            # click on AGREE, if it shows up\n",
    "            try:\n",
    "                agree = browser.find_elements_by_xpath(\"/html/body/div/div/div/div/div[2]/div[2]/form/button\")[0]\n",
    "                hover = ActionChains(browser).move_to_element(agree)\n",
    "                hover.perform()\n",
    "                agree.click()\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        print(str(i))\n",
    "        print(stock_names.loc[i].Names)\n",
    "        time.sleep(1)\n",
    "    \n",
    "    # In the end, quit the browser\n",
    "    browser.quit()\n",
    " \n",
    "    return(names)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Takes 4-5 hours !!\n",
    "\n",
    "INDICIES = get_indicies(#names)\n",
    "np.savetxt(path + \"indicies.csv\", INDICIES, delimiter=\",\", fmt='%s', encoding = \"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Check of Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.Series([])\n",
    "data = pd.read_csv(path + \"indicies.csv\", header = None, sep = \":\", encoding = \"ISO-8859-1\")\n",
    "df = df.append(data[0])\n",
    "\n",
    "display(len(df))\n",
    "df.reset_index(drop= True, inplace = True)\n",
    "\n",
    "# Percentage of errors\n",
    "display(len(df[df == \"error\"])/len(df))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Adding Indicies to Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names[\"Indicies\"] = df.copy() \n",
    "names.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Getting indicies out of parentheses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indicies(s):\n",
    "\n",
    "    x = s[s.find(\"(\")+1:s.find(\")\")]\n",
    "    return x\n",
    "\n",
    "names[\"Quotes\"] = names[\"Indicies\"].apply(indicies)\n",
    "names.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Check for Duplicates, Drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(len(names))\n",
    "\n",
    "# Check duplicates\n",
    "names[names[\"Quotes\"].duplicated( keep = False)].sort_values(by = [\"Quotes\"], axis=0)\n",
    "\n",
    "# Drop duplicates\n",
    "names.drop_duplicates(subset =\"Quotes\",keep = \"first\", inplace = True) \n",
    "names.reset_index(drop= True, inplace = True)\n",
    "\n",
    "display(len(names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Scraping daily data for Indicies\n",
    "### OLD VERSION, TOO SLOW  -> Try 5) !!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_dwn_OLD(stocks):\n",
    "\n",
    "    for i in stocks:\n",
    "        \n",
    "        # For each stock open browser - could be better ?\n",
    "        browser = webdriver.Chrome()\n",
    "                                                                 # This time period corresponds to all the history up to the 31.12.2019\n",
    "        url = \"https://finance.yahoo.com/quote/\" + str(i) + \"/history?period1=10104800&period2=1577919600&interval=1d&filter=history&frequency=1d\"\n",
    "                                \n",
    "        browser.get(url)\n",
    "\n",
    "        \n",
    "        # This clicks on AGREE, if there is a warning     \n",
    "        try:\n",
    "            agree = browser.find_elements_by_xpath(\"/html/body/div/div/div/div/div[2]/div[2]/form/button\")[0]\n",
    "            hover = ActionChains(browser).move_to_element(agree)\n",
    "            hover.perform()\n",
    "            agree.click()\n",
    "\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        sleep(2)\n",
    "        \n",
    "        # Clicks on Download -> CSV is downloaded\n",
    "        play = browser.find_elements_by_xpath('/html/body/div[1]/div/div/div[1]/div/div[3]/div[1]/div/div[2]/div/div/section/div[1]/div[2]/span[2]/a/span')[0]       \n",
    "        hover = ActionChains(browser).move_to_element(play)\n",
    "        hover.perform()\n",
    "        play.click()\n",
    "        \n",
    "        sleep(2)\n",
    "        \n",
    "        browser.quit()\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_dwn_OLD(names.Quotes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Scraping daily data for Indicies\n",
    "### Better version, YAHOO API instead of pressing download button. No Selenium needed\n",
    "*  3208 -> 3067 scraped\n",
    "* takes about 1 hour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1) Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = pd.read_excel(path + \"names_all.xlsx\")\n",
    "names.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_dwn(stocks):\n",
    "    \n",
    "    # One web browser window is needed\n",
    "    browser = webdriver.Chrome()\n",
    "    \n",
    "    # for all 3208 stocks, use API to download CSVs\n",
    "    for i in stocks:\n",
    "                                                                            # This time period corresponds to all the history up to the 31.12.2019\n",
    "        url = \"https://query1.finance.yahoo.com/v7/finance/download/\" + str(i) + \"?period1=10104800&period2=1577919600&interval=1d&events=history\"\n",
    "                                \n",
    "        browser.get(url)\n",
    "        sleep(0.5)\n",
    "    browser.quit()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes about 1 hour\n",
    "\n",
    "data_dwn(names.Quotes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.) Indicies -> Countries\n",
    "* In the orginal dataset ???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def country(x):\n",
    "    y = x.split(\".\")\n",
    "    if len(y) > 1:\n",
    "        return y[-1]\n",
    "    else:\n",
    "        return \"-\"\n",
    "\n",
    "names[\"Country\"] = names[\"Quotes\"].apply(country)\n",
    "names.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 List all countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries = names_all.Country.unique()\n",
    "display(len(countries))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names.groupby('Country')['Quotes'].nunique()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Currency - before\n",
    "AUD       9\n",
    "CAD      10\n",
    "CHF       5\n",
    "DKK       1\n",
    "EUR    1386\n",
    "GBP    1456\n",
    "HKD       2\n",
    "IDR       1\n",
    "INR      10\n",
    "JPY       2\n",
    "KRW       3\n",
    "MXN       1\n",
    "NOK       1\n",
    "RUB      20\n",
    "SGD       1\n",
    "THB       1\n",
    "TWD      11\n",
    "USD     287\n",
    "ZAC       1\n",
    "\n",
    "################\n",
    "\n",
    "Currency - after - see next file:)\n",
    "AUD       9\n",
    "CAD      10\n",
    "EUR    1386\n",
    "GBP    1456\n",
    "INR      10\n",
    "RUB      20\n",
    "TWD      11\n",
    "USD     287"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
